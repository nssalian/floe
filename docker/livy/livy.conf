# Livy configuration

# Allow sessions from any host
livy.server.host = 0.0.0.0

# Session configuration
livy.spark.master = local[*]
livy.spark.deploy-mode = client

# Disable authentication for local development
livy.rsc.rpc.sasl.enabled = false
livy.server.csrf-protection.enabled = false

# RSC (Remote Spark Context) settings - fix Docker networking
livy.rsc.server.connect.timeout = 120s
livy.rsc.rpc.server.address = livy
livy.rsc.launcher.address = livy

# Iceberg configuration - will be passed to Spark sessions
livy.spark.sql.extensions = org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
livy.spark.sql.catalog.demo = org.apache.iceberg.spark.SparkCatalog
livy.spark.sql.catalog.demo.type = rest
livy.spark.sql.catalog.demo.uri = http://rest:8181
livy.spark.sql.catalog.demo.warehouse = s3://warehouse/
livy.spark.sql.catalog.demo.io-impl = org.apache.iceberg.aws.s3.S3FileIO
livy.spark.sql.catalog.demo.s3.endpoint = http://minio:9000
livy.spark.sql.catalog.demo.s3.access-key-id = admin
livy.spark.sql.catalog.demo.s3.secret-access-key = password
livy.spark.sql.catalog.demo.s3.path-style-access = true

# S3A config for Spark
livy.spark.hadoop.fs.s3a.endpoint = http://minio:9000
livy.spark.hadoop.fs.s3a.access.key = admin
livy.spark.hadoop.fs.s3a.secret.key = password
livy.spark.hadoop.fs.s3a.path.style.access = true
livy.spark.hadoop.fs.s3a.impl = org.apache.hadoop.fs.s3a.S3AFileSystem
livy.spark.hadoop.fs.s3a.connection.ssl.enabled = false

# Session timeout (30 minutes)
livy.server.session.timeout = 30m

# Allow any file to be uploaded
livy.file.local-dir-whitelist = /tmp